{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1ZX1qsK8s7xVCwKWqQnbFx8vKTzPD-ILl","authorship_tag":"ABX9TyNwAjoIfUfs9xUXNZAkxWD4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":8,"metadata":{"id":"2OGHRvDqr-ES","executionInfo":{"status":"ok","timestamp":1721488718629,"user_tz":-120,"elapsed":260,"user":{"displayName":"Chethan DandebalaVenkatarama","userId":"18158647729901841482"}}},"outputs":[],"source":["import numpy as np\n","import tensorflow as tf\n","import matplotlib.pyplot as plt\n","from tensorflow.keras.models import load_model\n","from sklearn.model_selection import train_test_split\n","from tensorflow.keras.applications.inception_v3 import InceptionV3, preprocess_input\n","import cv2\n","import os"]},{"cell_type":"code","source":["# Helper function to load and preprocess images\n","def load_and_preprocess_image(path, target_size=(224, 224)):\n","    image = cv2.imread(path)\n","    image = cv2.resize(image, target_size)\n","    image = preprocess_input(image)\n","    return image"],"metadata":{"id":"ZVHSs17ztmFK","executionInfo":{"status":"ok","timestamp":1721488720509,"user_tz":-120,"elapsed":278,"user":{"displayName":"Chethan DandebalaVenkatarama","userId":"18158647729901841482"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["# Path definitions\n","real_dir = \"/content/drive/MyDrive/RealFake.zip (Unzipped Files)/real_and_fake_face/training_real/\"\n","fake_dir = \"/content/drive/MyDrive/RealFake.zip (Unzipped Files)/real_and_fake_face/training_fake/\"\n","\n","real_paths = [os.path.join(real_dir, fname) for fname in os.listdir(real_dir)]\n","fake_paths = [os.path.join(fake_dir, fname) for fname in os.listdir(fake_dir)]\n","\n","real_labels = [1] * len(real_paths)\n","fake_labels = [0] * len(fake_paths)\n","\n","all_paths = real_paths + fake_paths\n","all_labels = real_labels + fake_labels"],"metadata":{"id":"7VqFN7CJtoOX","executionInfo":{"status":"ok","timestamp":1721488722694,"user_tz":-120,"elapsed":301,"user":{"displayName":"Chethan DandebalaVenkatarama","userId":"18158647729901841482"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["# Split data into training and validation sets\n","train_paths, val_paths, train_labels, val_labels = train_test_split(all_paths, all_labels, test_size=0.2, random_state=42)"],"metadata":{"id":"YPzhie-Mtrb_","executionInfo":{"status":"ok","timestamp":1721488725100,"user_tz":-120,"elapsed":261,"user":{"displayName":"Chethan DandebalaVenkatarama","userId":"18158647729901841482"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["# Create sequences manually\n","def create_image_sequences(image_paths, labels, seq_length=10, image_size=(224, 224)):\n","    sequences = []\n","    sequence_labels = []\n","    for i in range(0, len(image_paths) - seq_length + 1, seq_length):\n","        sequence = [load_and_preprocess_image(image_paths[j], target_size=image_size) for j in range(i, i + seq_length)]\n","        sequences.append(np.array(sequence))\n","        sequence_labels.append(labels[i])\n","    return np.array(sequences), np.array(sequence_labels)"],"metadata":{"id":"lXd1QJlFtthE","executionInfo":{"status":"ok","timestamp":1721488728489,"user_tz":-120,"elapsed":261,"user":{"displayName":"Chethan DandebalaVenkatarama","userId":"18158647729901841482"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["# Prepare sequences\n","train_sequences, train_sequence_labels = create_image_sequences(train_paths, train_labels)\n","val_sequences, val_sequence_labels = create_image_sequences(val_paths, val_labels)"],"metadata":{"id":"iESk_BhJtvyg","executionInfo":{"status":"ok","timestamp":1721489529695,"user_tz":-120,"elapsed":799235,"user":{"displayName":"Chethan DandebalaVenkatarama","userId":"18158647729901841482"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["# Load models\n","model_inception = load_model('/content/drive/MyDrive/inceptionV3Deepfake_model.h5')\n","model_MobileNet = load_model('/content/drive/MyDrive/MobileNetV2Deepfake_model.h5')\n","model_Hybrid = load_model('/content/drive/MyDrive/hybrid_inception_lstm_model.h5')"],"metadata":{"id":"sCtpEEL7tyQC","executionInfo":{"status":"ok","timestamp":1721489707956,"user_tz":-120,"elapsed":38634,"user":{"displayName":"Chethan DandebalaVenkatarama","userId":"18158647729901841482"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["# Evaluate models\n","def evaluate_model(model, val_sequences, val_sequence_labels):\n","    results = model.evaluate(val_sequences, val_sequence_labels, verbose=0) # Evaluate the model using the original val_sequences, not the reshaped one\n","    return results\n","\n","# Evaluate models using the original sequences\n","results_inception = evaluate_model(model_inception, val_sequences, val_sequence_labels)\n","results_mobileNet = evaluate_model(model_MobileNet, val_sequences, val_sequence_labels)\n","results_hybrid = evaluate_model(model_Hybrid, val_sequences, val_sequence_labels)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":755},"id":"6VIn4-Pktz6g","executionInfo":{"status":"error","timestamp":1721490199506,"user_tz":-120,"elapsed":1057,"user":{"displayName":"Chethan DandebalaVenkatarama","userId":"18158647729901841482"}},"outputId":"44c6e2b3-861c-48d8-d3f5-a8a01eb8d3bf"},"execution_count":17,"outputs":[{"output_type":"error","ename":"ValueError","evalue":"in user code:\n\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 2066, in test_function  *\n        return step_function(self, iterator)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 2049, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 2037, in run_step  **\n        outputs = model.test_step(data)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1917, in test_step\n        y_pred = self(x, training=False)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/input_spec.py\", line 298, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"sequential\" is incompatible with the layer: expected shape=(None, 224, 224, 3), found shape=(None, 10, 224, 224, 3)\n","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-17-ebc243074c01>\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Evaluate models using the original sequences\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mresults_inception\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_inception\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_sequences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_sequence_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mresults_mobileNet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_MobileNet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_sequences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_sequence_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mresults_hybrid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_Hybrid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_sequences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_sequence_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-17-ebc243074c01>\u001b[0m in \u001b[0;36mevaluate_model\u001b[0;34m(model, val_sequences, val_sequence_labels)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Evaluate models\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mevaluate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_sequences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_sequence_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_sequences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_sequence_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Evaluate the model using the original val_sequences, not the reshaped one\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mtf__test_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                     \u001b[0mretval_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m                 \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 2066, in test_function  *\n        return step_function(self, iterator)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 2049, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 2037, in run_step  **\n        outputs = model.test_step(data)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1917, in test_step\n        y_pred = self(x, training=False)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/input_spec.py\", line 298, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"sequential\" is incompatible with the layer: expected shape=(None, 224, 224, 3), found shape=(None, 10, 224, 224, 3)\n"]}]},{"cell_type":"code","source":["# Collect results for comparison\n","model_names = [\"Inception LSTM\", \"Simple CNN\", \"Custom Model\"]\n","accuracies = [results_inception[1], results_mobileNet[1], results_hybrid[1]]\n","losses = [results_inception[0], results_mobileNet[0], results_hybrid[0]]"],"metadata":{"id":"yVhdkE2ht2ao","executionInfo":{"status":"aborted","timestamp":1721488645763,"user_tz":-120,"elapsed":7,"user":{"displayName":"Chethan DandebalaVenkatarama","userId":"18158647729901841482"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Visualization\n","def plot_final_accuracy(model_names, accuracies):\n","    plt.figure(figsize=(12, 8))\n","    plt.bar(model_names, accuracies, color=['blue', 'green', 'red'])\n","    plt.xlabel('Model')\n","    plt.ylabel('Accuracy')\n","    plt.title('Final Validation Accuracy of Models')\n","    plt.ylim(0, 1)\n","    plt.show()\n","\n","def plot_final_loss(model_names, losses):\n","    plt.figure(figsize=(12, 8))\n","    plt.bar(model_names, losses, color=['blue', 'green', 'red'])\n","    plt.xlabel('Model')\n","    plt.ylabel('Loss')\n","    plt.title('Final Validation Loss of Models')\n","    plt.show()"],"metadata":{"id":"logK6udIt4pG","executionInfo":{"status":"aborted","timestamp":1721488645764,"user_tz":-120,"elapsed":8,"user":{"displayName":"Chethan DandebalaVenkatarama","userId":"18158647729901841482"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Plot results\n","plot_final_accuracy(model_names, accuracies)\n","plot_final_loss(model_names, losses)\n"],"metadata":{"id":"XYX8hyQ7t7S4","executionInfo":{"status":"aborted","timestamp":1721488645764,"user_tz":-120,"elapsed":8,"user":{"displayName":"Chethan DandebalaVenkatarama","userId":"18158647729901841482"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","from tensorflow.keras.applications.inception_v3 import InceptionV3, preprocess_input\n","from tensorflow.keras.models import Model, load_model\n","from tensorflow.keras.layers import Dropout, Dense, GlobalAveragePooling2D, LSTM, TimeDistributed, Input\n","from tensorflow.keras.optimizers import SGD\n","from tensorflow.keras.callbacks import LearningRateScheduler\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","import matplotlib.pyplot as plt\n","import cv2\n","import os\n","\n","# Helper function to load and preprocess images\n","def load_and_preprocess_image(path, target_size=(224, 224)):\n","    image = cv2.imread(path)\n","    image = cv2.resize(image, target_size)\n","    image = preprocess_input(image)\n","    return image\n","\n","# Path definitions\n","real_dir = \"/content/drive/MyDrive/RealFake.zip (Unzipped Files)/real_and_fake_face/training_real/\"\n","fake_dir = \"/content/drive/MyDrive/RealFake.zip (Unzipped Files)/real_and_fake_face/training_fake/\"\n","\n","real_paths = [os.path.join(real_dir, fname) for fname in os.listdir(real_dir)]\n","fake_paths = [os.path.join(fake_dir, fname) for fname in os.listdir(fake_dir)]\n","\n","real_labels = [1] * len(real_paths)\n","fake_labels = [0] * len(fake_paths)\n","\n","all_paths = real_paths + fake_paths\n","all_labels = real_labels + fake_labels\n","\n","# Split data into training and validation sets\n","from sklearn.model_selection import train_test_split\n","train_paths, val_paths, train_labels, val_labels = train_test_split(all_paths, all_labels, test_size=0.2, random_state=42)\n","\n","# Create sequences manually\n","def create_image_sequences(image_paths, labels, seq_length=10, image_size=(224, 224)):\n","    sequences = []\n","    sequence_labels = []\n","    for i in range(0, len(image_paths) - seq_length + 1, seq_length):\n","        sequence = [load_and_preprocess_image(image_paths[j], target_size=image_size) for j in range(i, i + seq_length)]\n","        sequences.append(np.array(sequence))\n","        sequence_labels.append(labels[i])\n","    return np.array(sequences), np.array(sequence_labels)\n","\n","train_sequences, train_sequence_labels = create_image_sequences(train_paths, train_labels)\n","val_sequences, val_sequence_labels = create_image_sequences(val_paths, val_labels)\n","\n","# Function to create and compile a model\n","def create_model(model_type, input_shape):\n","    model_input = Input(shape=input_shape)\n","    if model_type == \"inception_lstm\":\n","        base_model = InceptionV3(include_top=False, weights=\"imagenet\", input_shape=image_size + (3,))\n","        for layer in base_model.layers:\n","            layer.trainable = False\n","        cnn = TimeDistributed(base_model)(model_input)\n","        cnn = TimeDistributed(GlobalAveragePooling2D())(cnn)\n","        lstm = LSTM(256, return_sequences=True)(cnn)\n","        lstm = LSTM(256)(lstm)\n","        fc = Dense(512, activation=\"relu\")(lstm)\n","        fc = Dropout(0.5)(fc)\n","        fc = Dense(256, activation=\"relu\")(fc)\n","        fc = Dropout(0.5)(fc)\n","        output = Dense(1, activation=\"sigmoid\")(fc)\n","    elif model_type == \"simple_cnn\":\n","        base_model = InceptionV3(include_top=False, weights=\"imagenet\", input_shape=image_size + (3,))\n","        for layer in base_model.layers:\n","            layer.trainable = False\n","        cnn = TimeDistributed(base_model)(model_input)\n","        cnn = TimeDistributed(GlobalAveragePooling2D())(cnn)\n","        flatten = TimeDistributed(Dense(512, activation=\"relu\"))(cnn)\n","        output = Dense(1, activation=\"sigmoid\")(flatten)\n","    else:  # Custom model example\n","        base_model = InceptionV3(include_top=False, weights=\"imagenet\", input_shape=image_size + (3,))\n","        for layer in base_model.layers:\n","            layer.trainable = False\n","        cnn = TimeDistributed(base_model)(model_input)\n","        cnn = TimeDistributed(GlobalAveragePooling2D())(cnn)\n","        lstm = LSTM(128, return_sequences=True)(cnn)\n","        lstm = LSTM(128)(lstm)\n","        fc = Dense(256, activation=\"relu\")(lstm)\n","        fc = Dropout(0.5)(fc)\n","        fc = Dense(128, activation=\"relu\")(fc)\n","        fc = Dropout(0.5)(fc)\n","        output = Dense(1, activation=\"sigmoid\")(fc)\n","\n","    model = Model(inputs=model_input, outputs=output)\n","    opt = SGD(learning_rate=0.01)\n","    model.compile(loss=\"binary_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])\n","    return model\n","\n","# Training and evaluating the models\n","def train_and_evaluate(model_type, train_sequences, train_sequence_labels, val_sequences, val_sequence_labels):\n","    seq_length = 10\n","    image_size = (224, 224)\n","    input_shape = (seq_length, *image_size, 3)\n","    model = create_model(model_type, input_shape)\n","\n","    def scheduler(epoch):\n","        if epoch <= 1:\n","            return 1.0\n","        elif epoch > 2 and epoch <= 10:\n","            return 0.1\n","        elif epoch > 10 and epoch <= 15:\n","            return 0.01\n","        else:\n","            return 0.001\n","\n","    lr_callbacks = LearningRateScheduler(scheduler)\n","\n","    hist = model.fit(train_sequences, train_sequence_labels,\n","                     epochs=20,\n","                     batch_size=8,\n","                     callbacks=[lr_callbacks],\n","                     validation_data=(val_sequences, val_sequence_labels))\n","\n","    return hist.history\n","\n","# Compare 3 models\n","history_inception_lstm = train_and_evaluate(\"inception_lstm\", train_sequences, train_sequence_labels, val_sequences, val_sequence_labels)\n","history_simple_cnn = train_and_evaluate(\"simple_cnn\", train_sequences, train_sequence_labels, val_sequences, val_sequence_labels)\n","history_custom_model = train_and_evaluate(\"custom_model\", train_sequences, train_sequence_labels, val_sequences, val_sequence_labels)\n","\n","# Visualization\n","def plot_history(histories, title):\n","    plt.figure(figsize=(12, 8))\n","    for name, history in histories.items():\n","        plt.plot(history['accuracy'], label=f'{name} train accuracy')\n","        plt.plot(history['val_accuracy'], label=f'{name} val accuracy')\n","    plt.title(title)\n","    plt.xlabel('Epochs')\n","    plt.ylabel('Accuracy')\n","    plt.legend()\n","    plt.show()\n","\n","def plot_loss(histories, title):\n","    plt.figure(figsize=(12, 8))\n","    for name, history in histories.items():\n","        plt.plot(history['loss'], label=f'{name} train loss')\n","        plt.plot(history['val_loss'], label=f'{name} val loss')\n","    plt.title(title)\n","    plt.xlabel('Epochs')\n","    plt.ylabel('Loss')\n","    plt.legend()\n","    plt.show()\n","\n","def plot_final_accuracy(histories):\n","    final_train_accuracies = [history['accuracy'][-1] for history in histories.values()]\n","    final_val_accuracies = [history['val_accuracy'][-1] for history in histories.values()]\n","    model_names = list(histories.keys())\n","\n","    plt.figure(figsize=(12, 8))\n","    bar_width = 0.35\n","    index = np.arange(len(model_names))\n","\n","    plt.bar(index, final_train_accuracies, bar_width, label='Train Accuracy')\n","    plt.bar(index + bar_width, final_val_accuracies, bar_width, label='Val Accuracy')\n","\n","    plt.xlabel('Model')\n","    plt.ylabel('Accuracy')\n","    plt.title('Final Training and Validation Accuracy')\n","    plt.xticks(index + bar_width / 2, model_names)\n","    plt.legend()\n","    plt.show()\n","\n","histories = {\n","    \"Inception LSTM\": history_inception_lstm,\n","    \"Simple CNN\": history_simple_cnn,\n","    \"Custom Model\": history_custom_model\n","}\n","\n","plot_history(histories, \"Model Accuracy Comparison\")\n","plot_loss(histories, \"Model Loss Comparison\")\n","plot_final_accuracy(histories)\n"],"metadata":{"id":"1Mn0DjQfy1XI"},"execution_count":null,"outputs":[]}]}